Запуск контейнеров:
docker-compose up
docker-compose -f docker-compose-v3.yml up


docker ps

docker cp data/customer_shopping_data.csv namenode:/ #загрузить данные

docker cp data/data.csv namenode:/ #загрузить данные  

docker exec -it namenode bash

hdfs dfs -D dfs.block.size=16M -put /customer_shopping_data.csv /

hdfs dfs -D dfs.block.size=32M -put /data.csv /
   
hdfs dfsadmin -setSpaceQuota 10g / #ограничение на используемую память

hdfs dfsadmin -report

hdfs dfsadmin -safemode get

hdfs dfsadmin -safemode leave

exit

docker cp ./spark_app.py spark-master:/
docker cp ./Spark.sh spark-master:/ 

docker exec -it spark-master bash Spark.sh False

docker cp spark-master:/log.txt ./logs/DataNodes_1_opt_False.txt

docker exec -it spark-master bash Spark.sh True

docker cp spark-master:/log.txt ./logs/DataNodes_1_opt_True.txt

docker exec -it spark-master bash Spark.sh False

docker cp spark-master:/log.txt ./logs/DataNodes_3_opt_False.txt

docker exec -it spark-master bash Spark.sh True

docker cp spark-master:/log.txt ./logs/DataNodes_3_opt_True.txt

exit

Отключение docker-compose
docker-compose down

Ссылки для Hadoop и Spark:
http://localhost:9870
http://localhost:9870/explorer.html#/
http://localhost:8080/
http://localhost:8081/
http://localhost:4040/jobs/
